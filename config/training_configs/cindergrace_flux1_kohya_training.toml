# Kohya FLUX LoRA Training Configuration
# Generated for: cindergrace_flux1
# Trigger word: cindergrace

[model_arguments]
pretrained_model_name_or_path = "/home/zorinadmin/comfyui/production/ComfyUI/models/diffusion_models/flux1-krea-dev.safetensors"
ae = "/home/zorinadmin/comfyui/production/ComfyUI/models/vae/ae.safetensors"
clip_l = "/home/zorinadmin/comfyui/production/ComfyUI/models/text_encoders/clip_l.safetensors"
t5xxl = "/home/zorinadmin/comfyui/production/ComfyUI/models/text_encoders/t5xxl_fp8_e4m3fn.safetensors"

[network_arguments]
network_module = "networks.lora_flux"
network_dim = 16
network_alpha = 8

[optimizer_arguments]
optimizer_type = "prodigy"
learning_rate = 1.0

[training_arguments]
output_dir = "/home/zorinadmin/comfyui/production/ComfyUI/models/loras"
output_name = "cg_cindergrace_flux1"
save_model_as = "safetensors"
max_train_steps = 1500
mixed_precision = "bf16"
gradient_checkpointing = true
gradient_accumulation_steps = 4
seed = 42
save_every_n_steps = 500
cache_latents = true
cache_latents_to_disk = true
cache_text_encoder_outputs = true
cache_text_encoder_outputs_to_disk = true
fp8_base = true

[flux_arguments]
blocks_to_swap = 20
t5xxl_max_token_length = 512
guidance_scale = 1.0

[dataset]
dataset_config = "/home/zorinadmin/projekte/cindergrace_gui/config/training_configs/cindergrace_flux1_dataset.toml"
